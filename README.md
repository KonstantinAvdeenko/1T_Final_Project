Проект № 7
Данный проект берет за основу проект № 2, но с иным источником извлечения данных и расширенным функционалом.
Анализ рынка курса акций самых популярных российских компаний.

Общая задача: создать ETL-процесс формирования витрин данных для анализа изменений курса акций.

Подробное описание задачи:

1. Разработка скрипты загрузки данных в 2-х режимах:

- Инициализирующий — загрузка полного слепка данных источника
- Инкрементальный — загрузка дельты данных за прошедшие сутки

2. Организация структуры хранения данных:

- Сырой слой данных
- Промежуточный слой
- Слой витрин.
Описание проекта.
Проект разработан для загрузки и анализа данных о ценах акций на Московской Бирже. В качестве источника данных используется открытый API Московской биржи: http://iss.moex.com/iss/.

Исследуем данные по акциям предприятий:

GAZP - Gazprom (Газпром) - крупный российский энергетический концерн, занимающийся добычей, переработкой, транспортом и продажей природного газа.
SBER - Sberbank (Сбербанк) - крупнейший банк России и один из ведущих финансовых институтов СНГ, предоставляющий широкий спектр банковских услуг.
GMKN - Norilsk Nickel (Норильский никель) - российская металлургическая компания и один из крупнейших мировых производителей никеля, палладия, платины и меди.
VTBR - VTB Bank (ВТБ Банк) - один из крупнейших банков России, оказывающий широкий спектр финансовых услуг для корпоративных и частных клиентов. Банк активно занимается инвестированием в различные отрасли экономики, в том числе в финансовый сектор, розничную торговлю, производство и недвижимость.
YNDX - Yandex (Яндекс) - это крупнейшая российская интернет-компания, специализирующаяся на разработке и предоставлении услуг в области поисковой системы, электронной коммерции, интернет-медиа, онлайн-транспорт и других сферах.
Размер извлекаемых данных не считается большим, поскольку при использовании интервала в 60 минут мы получаем порядка 30 000 строк, а при интервале в 10 минут - порядка 170 000 строк. В связи с этим было принято решение использовать PostgreSQL для хранения и обработки данных, а для создания конвейера, включающего сбор, сохранение, преобразование и агрегацию данных для построения витрин - Apache Airflow.

Структура директории проекта и его запуск
tree.png

В терминале перейти в папку Project_files и выполнить команду docker-compose up -d;

Перейти в WEB-интерфейс Airflow по ссылке http://localhost:8080/ (login: airflow, password: airflow) и прописать настройки подключения в Admin -> Connections (пароль password): connection.png

Параметры Variables прописаны в конфигурационном файле config.json и загружаются в Airflow автоматически;

Запустить в ручном режиме one_time_start_dag (отслеживать в logs полного исполнения Dag);

Для первого запуска daily_update_dag нужно прописать время его запуска в коде (изменить schedule_interval='45 05 * * *'):

 daily_update_dag = DAG(dag_id='daily_update_dag',
                tags=['daily_update'],
                start_date=datetime(2023, 9, 9),
                # schedule_interval=timedelta(days=1),
                catchup=False,
                schedule_interval='45 05 * * *',
                default_args=default_args)
❗Запускать принудительно - не по расписанию - категорически не рекомендуется во избежание дублирования записей в БД.

В случае дублирования записей при первичном запуске Dag вручную рекомендуется запустить его еще раз для перезаписи данных.

Структура проекта
Проект состоит из двух основных рабочих процессов (DAGs) в Apache Airflow:
1. Процесс one_time_start_dag: запускается вручную для сбора исторических данных и их загрузки в базу данных PostgreSQL.
create_csv_files: скачивание исторических данных (60-минутные свечи) с API Московской биржи и сохранение их в CSV-файлах.

create_raw_tables: создание отношений в базе данных РostgreSQL (Raw layer);

load_data: загрузка данных из CSV-файлов в Raw - слой;

execute_ddl: создание таблиц на слое Core;

execute_dml: заполнение таблиц на слое Core.

GRAPH:

one_time_start_graph.png

DAG:
one_time_start_dag.png

2. Процесс daily_update_dag: запускается ежедневно для сбора и анализа новых данных за последний день.
Выполняет следующие задачи:

downl_raw_last_day: скачивание данных за последний день и сохранение их в таблицах базы данных;

create_data_mart: создание витрины (агрегированные данные) на основе обновленной информации за последний день;

create_statistic_mart: создание витрины с обновленными статистическими данными за всю историю;

GRAPH:

daily_update_graph.png

DAG:
daily_update_dag.png

Графическая структура проекта:
plant_UML_big2.png

Результаты
ER - диаграмма сформированных данных:
ER_with_names.png

В результате выполнения проекта создаются витрины с обновленными данными по акциям:
1. Витрина data_mart, содержащая данные по акциям за последний день:
Суррогатный ключ категории;
Название акции;
Суммарный объем торгов за последние сутки;
Курс акций на момент открытия торгов для данных суток;
Курс акций на момент закрытия торгов для данных суток;
Разница (в %) курса с момента открытия до момента закрытия торгов для данных суток;
Минимальный временной интервал, на котором был зафиксирован самый крупный объем торгов для данных суток;
Минимальный временной интервал, на котором был зафиксирован максимальный курс для данных суток;
Минимальный временной интервал, на котором был зафиксирован минимальный курс торгов для данных суток.

2. Витрина statistic_mart, содержащая статистические данные по акциям за всю историю хранения данных:
Суррогатный ключ категории;
Название акции;
Первый день исторических данных;
Последний загруженный день;
Максимальная сумма продаж за всю историю на интервале 60 минут;
Дата максимальной суммы оборота акций;
Минимальная сумма продаж за всю историю на интервале 60 минут;
Дата минимальной суммы оборота акций;
Максимальный количественный объем продаж за всю историю на интервале 60 минут;
Дата максимального объема продаж акций;
Минимальный количественный объем продаж за всю историю на интервале 60 минут;
Дата минимального объема продаж акций;
Максимальная цена продаж акций за всю историю хранения данных;
Дата зафиксированной максимальной цены акции;
Минимальная цена продаж акций за всю историю хранения данных;
Дата зафиксированной минимальной цены акции.
